{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0Tw1Co8AJn8g",
   "metadata": {
    "id": "0Tw1Co8AJn8g"
   },
   "source": [
    "# Loading code and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zf7OJapVZoYf",
   "metadata": {
    "id": "zf7OJapVZoYf"
   },
   "source": [
    "## When loading notebook for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mg-t0ddTD9Ei",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51209,
     "status": "ok",
     "timestamp": 1702411812162,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "Mg-t0ddTD9Ei",
    "outputId": "6ced12e3-9ded-4b42-b9da-4f428e83f433"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9mhBcLrMBaOq",
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1702408215765,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "9mhBcLrMBaOq"
   },
   "outputs": [],
   "source": [
    "!mkdir /root/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vJBjVq7lHYjo",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702408219996,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "vJBjVq7lHYjo"
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "########## Add kaggle API key ##########\n",
    "########################################\n",
    "\n",
    "!echo '{\"username\":\"aliceallafort\",\"key\":\"0d34479935dac419278ed5dce8d32974\"}' > ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IEnUWbWxIBuA",
   "metadata": {
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1702408223263,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "IEnUWbWxIBuA"
   },
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IySzbFPFHZY9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3416,
     "status": "ok",
     "timestamp": 1702408229998,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "IySzbFPFHZY9",
    "outputId": "5e66c584-0025-4ac1-b2bf-7d16dd253387"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/TigerManon/drive-on-mars.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imC60Kq5Ho_E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1702408232502,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "imC60Kq5Ho_E",
    "outputId": "4ecd1145-3bda-41e2-c55c-4f00497696db"
   },
   "outputs": [],
   "source": [
    "%cd drive-on-mars/\n",
    "%mkdir raw_data\n",
    "%cd raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rqG8nTFDH7KH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294344,
     "status": "ok",
     "timestamp": 1702408530911,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "rqG8nTFDH7KH",
    "outputId": "a0a0838f-f325-4c61-ea9b-2392dfa8ca2f"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download yash92328/ai4mars-terrainaware-autonomous-driving-on-mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AUQYfYqrI8bi",
   "metadata": {
    "executionInfo": {
     "elapsed": 53060,
     "status": "ok",
     "timestamp": 1702408622956,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "AUQYfYqrI8bi"
   },
   "outputs": [],
   "source": [
    "!unzip -q ai4mars-terrainaware-autonomous-driving-on-mars.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8kpvjc4oKjQn",
   "metadata": {
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1702408645896,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "8kpvjc4oKjQn"
   },
   "outputs": [],
   "source": [
    "!rm ai4mars-terrainaware-autonomous-driving-on-mars.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0tgOdFRLK7Ni",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702408649087,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "0tgOdFRLK7Ni",
    "outputId": "abc9bba6-c805-4bc2-9460-5a429658710c"
   },
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdGILbFVn3x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1702408652090,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "afdGILbFVn3x",
    "outputId": "6e62dbf0-4d15-4e8f-f751-a4ecc8618ec5"
   },
   "outputs": [],
   "source": [
    "%ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mhQ0992mZs2b",
   "metadata": {
    "id": "mhQ0992mZs2b"
   },
   "source": [
    "## When reloading the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X7HDreGiblbv",
   "metadata": {
    "id": "X7HDreGiblbv"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5mFI0TVpVorV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1702049877490,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "5mFI0TVpVorV",
    "outputId": "dc161bc8-fdd5-4bf7-8bb6-fccc410c9a68"
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NBQHw-HXKu1F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1702049879743,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "NBQHw-HXKu1F",
    "outputId": "4b0930cd-50fc-4773-a8d2-395a0a94666b"
   },
   "outputs": [],
   "source": [
    "%cd drive-on-mars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3--DYx45KvD4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1702053743295,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "3--DYx45KvD4",
    "outputId": "efb9dd45-53d5-436c-a23f-2409b2475718"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30bac1b6",
   "metadata": {
    "id": "30bac1b6"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8240c6",
   "metadata": {
    "id": "9a8240c6"
   },
   "source": [
    "# Loading Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a7176a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7374,
     "status": "ok",
     "timestamp": 1702408677402,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "b5a7176a",
    "outputId": "4fddc2c7-03c1-4d3f-8198-376c1a329198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation_models in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from segmentation_models) (1.0.8)\n",
      "Requirement already satisfied: image-classifiers==1.0.0 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from segmentation_models) (1.0.0)\n",
      "Requirement already satisfied: efficientnet==1.0.0 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from segmentation_models) (1.0.0)\n",
      "Requirement already satisfied: scikit-image in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.23.4)\n",
      "Requirement already satisfied: h5py in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.7.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.8.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.7)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (9.1.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.22.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from packaging>=20.0->scikit-image->efficientnet==1.0.0->segmentation_models) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/qubvel/segmentation_models\n",
    "!pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8694e0",
   "metadata": {
    "executionInfo": {
     "elapsed": 4527,
     "status": "ok",
     "timestamp": 1702408686892,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "ee8694e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 01:41:22.516223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 01:41:22.736703: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 01:41:22.748029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-13 01:41:22.748047: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-13 01:41:22.797266: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 01:41:23.696065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-13 01:41:23.696166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-13 01:41:23.696173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Data Visualisation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3MODcth_MA6n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702408690087,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "3MODcth_MA6n",
    "outputId": "1940369c-1a2a-4e13-fcb2-44ed0340a39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# Segmentation Models\n",
    "\n",
    "############# Alice #################\n",
    "# Had to add this to make sm work in colab\n",
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "from tensorflow import keras\n",
    "import segmentation_models as sm\n",
    "#####################################\n",
    "\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models.losses import CategoricalFocalLoss, DiceLoss\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oKNNi81Jt7R0",
   "metadata": {
    "id": "oKNNi81Jt7R0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "oCOOiasPt72W",
   "metadata": {
    "id": "oCOOiasPt72W"
   },
   "source": [
    "# ResNet Backbone Model Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m5EONsQ0M4-m",
   "metadata": {
    "id": "m5EONsQ0M4-m"
   },
   "source": [
    "## Data Generator for ResNet Backbone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xo8xisn2fkNU",
   "metadata": {
    "id": "xo8xisn2fkNU"
   },
   "outputs": [],
   "source": [
    "# 0 - soil\n",
    "# 1 - bedrock\n",
    "# 2 - sand\n",
    "# 3 - big rock\n",
    "# 255 -> 4 - NULL (no label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wud0t0qkbBAc",
   "metadata": {
    "executionInfo": {
     "elapsed": 817,
     "status": "ok",
     "timestamp": 1702408706659,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "wud0t0qkbBAc"
   },
   "outputs": [],
   "source": [
    "# Define a customized data generator\n",
    "class UnetDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_folder, label_folder, input_shape, batch_size, num_classes, subfolder, split_percent, use_mask = False):\n",
    "        self.image_folder       = image_folder\n",
    "        self.label_folder       = label_folder\n",
    "        self.input_shape        = input_shape\n",
    "        self.batch_size         = batch_size\n",
    "        self.num_classes        = num_classes\n",
    "        self.subfolder          = subfolder\n",
    "        self.split_percent      = split_percent\n",
    "        self.path_df            = self.make_df()\n",
    "        self.split_df()\n",
    "        self.use_mask           = use_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        print(\"Length of generator:\", len(self.path_df))\n",
    "        return math.ceil(len(self.path_df) / float(self.batch_size))    \n",
    "    \n",
    "    def make_df(self):      \n",
    "        img_list = [f for f in os.listdir(self.image_folder) if f.endswith('.JPG')]\n",
    "        lab_list = [f for f in os.listdir(self.label_folder) if f.endswith('.png')]\n",
    "\n",
    "        \n",
    "        path_df = pd.DataFrame(columns=[\"image_path\", \"label_path\", \"rover_mask_path\", \"range_mask_path\"])\n",
    "\n",
    "        for label_name in lab_list:\n",
    "            if self.subfolder in (\"train\", \"val\"):\n",
    "                image_name = label_name.replace('.png', '.JPG')\n",
    "                rover_mask_name = label_name.replace('EDR', 'MXY')  \n",
    "                range_mask_name = label_name.replace('EDR', 'RNG')  \n",
    "                \n",
    "            elif self.subfolder == 'test':\n",
    "                image_name = label_name.replace('_merged.png', '.JPG')\n",
    "                rover_mask_name = label_name.replace('_merged.png', '.png').replace('EDR', 'MXY')   \n",
    "                range_mask_name = label_name.replace('_merged.png', '.png').replace('EDR', 'RNG')  \n",
    "            \n",
    "            parent_folder = os.path.dirname(self.image_folder)\n",
    "            rover_mask_path = os.path.join(parent_folder,'mxy', rover_mask_name)\n",
    "            range_mask_path = os.path.join(parent_folder,'rng-30m', range_mask_name)\n",
    "\n",
    "            if image_name in img_list and os.path.exists(rover_mask_path) and os.path.exists(range_mask_path):\n",
    "                new_row = pd.DataFrame([{\n",
    "                \"image_path\": os.path.join(self.image_folder, image_name),\n",
    "                \"label_path\": os.path.join(self.label_folder, label_name),\n",
    "                \"rover_mask_path\": rover_mask_path,\n",
    "                \"range_mask_path\": range_mask_path\n",
    "                }])\n",
    "                path_df = pd.concat([path_df, new_row], ignore_index=True)\n",
    "        \n",
    "        return path_df\n",
    "\n",
    "  \n",
    "    \n",
    "    def split_df(self):\n",
    "        if self.subfolder in [\"train\",\"test\"]:\n",
    "            self.path_df = self.path_df.iloc[:int(len(self.path_df) * self.split_percent)]\n",
    "        elif self.subfolder == \"val\":\n",
    "            self.path_df = self.path_df.iloc[int(len(self.path_df) * self.split_percent):]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_images  = []\n",
    "        output_targets = []\n",
    "\n",
    "        #-------------------------------#\n",
    "        #   Calculate start indice and end indice of the batch\n",
    "        #-------------------------------#  \n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.path_df)) # Make sure that we can load all the data of the last batch\n",
    "\n",
    "        for i in range(start, end):  \n",
    "            \n",
    "            #-------------------------------#\n",
    "            #   Get image,label,rover mask and range mask path of each batch from path_df\n",
    "            #-------------------------------#                     \n",
    "            jpg = self.path_df.iloc[i][\"image_path\"]\n",
    "            png = self.path_df.iloc[i][\"label_path\"]\n",
    "            rover = self.path_df.iloc[i][\"rover_mask_path\"]\n",
    "            rng = self.path_df.iloc[i][\"range_mask_path\"]\n",
    "            \n",
    "            #-------------------------------#\n",
    "            #   Load both range and rover masks combined\n",
    "            #-------------------------------#           \n",
    "            rover_array = cv2.imread(rover)\n",
    "            rng_array = cv2.imread(rng)\n",
    "            # reversing mask to only keep the image out of the mask\n",
    "            mask_combined = (1-rover_array) * (1-rng_array)\n",
    "      \n",
    "            #-------------------------------#\n",
    "            #   Transform images and labels to numpy array, resize them\n",
    "            #   Set the background label to 4\n",
    "            #-------------------------------#\n",
    "\n",
    "            jpg = cv2.imread(jpg)\n",
    "            if self.use_mask:\n",
    "                jpg = jpg * mask_combined            \n",
    "            \n",
    "            png = cv2.imread(png,0)\n",
    "                \n",
    "            jpg = cv2.resize(jpg, dsize = (int(self.input_shape[0]), int(self.input_shape[1])))\n",
    "            png = cv2.resize(png, dsize = (int(self.input_shape[0]), int(self.input_shape[1])), \n",
    "                                      interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            png[png == 255] = 4\n",
    "\n",
    "            #-------------------------------------------------------#\n",
    "            #   One hot encode the labels\n",
    "            #-------------------------------------------------------#\n",
    "                \n",
    "            seg_labels = np.eye(self.num_classes)[png.reshape([-1])]                \n",
    "            seg_labels = seg_labels.reshape((int(self.input_shape[0]), int(self.input_shape[1]), self.num_classes))\n",
    "\n",
    "            input_images.append(jpg)\n",
    "            output_targets.append(seg_labels)\n",
    "\n",
    "        input_images = np.asarray(input_images)\n",
    "        output_targets = np.array(output_targets)\n",
    "\n",
    "        \n",
    "        return input_images, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and label directories paths in COLAB\n",
    "\n",
    "# image_folder = \"raw_data/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "# label_folder = \"raw_data/ai4mars-dataset-merged-0.1/msl/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and label directories paths in LOCAL\n",
    "image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "label_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9V9o6bwJL_uq",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1702408712808,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "9V9o6bwJL_uq"
   },
   "outputs": [],
   "source": [
    "# Some inputs\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "input_shape = (256,256,3)\n",
    "split_percent = 0.8\n",
    "height=input_shape[0]\n",
    "width=input_shape[1]\n",
    "channels=input_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xHkb5UWGNvrP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34517,
     "status": "ok",
     "timestamp": 1702408750306,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "xHkb5UWGNvrP",
    "outputId": "16d4b5ef-4223-4fdf-9b19-355e8bcb3f53"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train dataset generator and validation dataset generator\n",
    "traingen = UnetDataGenerator(image_folder,\n",
    "                             label_folder,\n",
    "                             input_shape,\n",
    "                             batch_size,\n",
    "                             num_classes,\n",
    "                             \"train\",\n",
    "                             split_percent,\n",
    "                            use_mask = True)\n",
    "\n",
    "valgen = UnetDataGenerator(image_folder,\n",
    "                           label_folder,\n",
    "                           input_shape,\n",
    "                           batch_size,\n",
    "                           num_classes,\n",
    "                           \"val\",\n",
    "                           split_percent,\n",
    "                          use_mask = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9xz4kNcZT",
   "metadata": {
    "id": "c6e9xz4kNcZT"
   },
   "source": [
    "## ResNet Backbone Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8-CJNCjcNbhB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7603,
     "status": "ok",
     "timestamp": 1702408808082,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "8-CJNCjcNbhB",
    "outputId": "5f00f583-5b53-4576-eb58-587f6ac47a73"
   },
   "outputs": [],
   "source": [
    "#%% pre-trained model\n",
    "\n",
    "# backbone choices: resnet34' resnet50' resnet101'\n",
    "BACKBONE = 'resnet50'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# define model\n",
    "# encoder_freeze=True (encoder_freeze: if ``True`` set all layers of encoder (backbone model) as non-trainable, default value is False.)\n",
    "# input_shape: shape of input data/image ``(H, W, C)``, in general case you do not need to set ``H`` and ``W`` shapes, just pass ``(None, None, C)`` to make your model be able to process images af any size, but ``H`` and ``W`` of input images should be divisible by factor ``32``.\n",
    "# decoder_filters=(256, 128, 64, 32, 16)\n",
    "# input_shape=(None, None, 3)\n",
    "model_resnet_backbone = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=num_classes, activation='softmax', encoder_freeze=True)\n",
    "\n",
    "model_resnet_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TSh1i0Z5NbQ_",
   "metadata": {
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1702408891411,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "TSh1i0Z5NbQ_"
   },
   "outputs": [],
   "source": [
    "# compile model with defined optimozer, loss and metrics\n",
    "\n",
    "# loss: dice_loss\n",
    "categorical_focal_loss = CategoricalFocalLoss()\n",
    "dice_loss = DiceLoss()\n",
    "categorical_focal_dice_loss = categorical_focal_loss + dice_loss\n",
    "# categorical_focal_jaccard_loss = categorical_focal_loss + jaccard_loss\n",
    "# iou_score = IOUScore() (threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round, as: metrics = [sm.metrics.IOUScore(threshold=0.5)])\n",
    "# class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.\n",
    "metrics=['accuracy', iou_score]\n",
    "\n",
    "model_resnet_backbone.compile(optimizer='adam',loss=categorical_focal_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "StPoWijGAA4a",
   "metadata": {
    "id": "StPoWijGAA4a"
   },
   "source": [
    "## ResNet Backbone Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288daf46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2664666,
     "status": "ok",
     "timestamp": 1702411602636,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "288daf46",
    "outputId": "2a51bcde-4284-40a4-d76c-a5cac28fe1b1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "MODEL = \"Unet_Res50_Unfreeze_ImageNet_WithMasks_256pix\"\n",
    "\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format(MODEL),\n",
    "                                            monitor=\"val_iou_score\",\n",
    "                                            save_best_only = False)\n",
    "\n",
    "LR_reducer = callbacks.ReduceLROnPlateau(patience = 3,\n",
    "                                         monitor=\"val_iou_score\",\n",
    "                                         factor = 0.1,\n",
    "                                         min_lr = 0\n",
    "                                        )\n",
    "\n",
    "early_stopper = callbacks.EarlyStopping(patience = 5,\n",
    "                                        monitor=\"val_iou_score\",\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "history_res_backbone = model_resnet_backbone.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=100,\n",
    "          callbacks = [modelCheckpoint, LR_reducer, early_stopper],\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J0NeXLQztNru",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1702411735173,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "J0NeXLQztNru",
    "outputId": "a17560ca-b12d-4991-fbe5-e59a19bd3bfb"
   },
   "outputs": [],
   "source": [
    "history_res_backbone.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wit3L9igZSg-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 1289,
     "status": "ok",
     "timestamp": 1702411741957,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "Wit3L9igZSg-",
    "outputId": "7205c079-bace-4d20-fb89-4f9df6b86957"
   },
   "outputs": [],
   "source": [
    "def plot_history(history_res_backbone, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history_res_backbone.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history_res_backbone.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history_res_backbone.history['iou_score'], label='train iou'  + exp_name)\n",
    "    ax2.plot(history_res_backbone.history['val_iou_score'], label='val iou'  + exp_name)\n",
    "    ax2.set_ylim(0, 0.7)\n",
    "    ax2.set_title('iou')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_res_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aam7UtqMnzEv",
   "metadata": {
    "id": "aam7UtqMnzEv"
   },
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nk_EIR8HJIcm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702411752798,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "Nk_EIR8HJIcm",
    "outputId": "e1eafff1-2f3a-44a1-d69c-0b6f2530c3f8"
   },
   "outputs": [],
   "source": [
    "!mkdir raw_data/models\n",
    "!ls raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fhwtZHreJJYe",
   "metadata": {
    "executionInfo": {
     "elapsed": 1523,
     "status": "ok",
     "timestamp": 1702411861601,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "fhwtZHreJJYe"
   },
   "outputs": [],
   "source": [
    "model_resnet_backbone.save(f'raw_data/models/{MODEL}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ySdWAY_CJJcT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1702411863882,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "ySdWAY_CJJcT",
    "outputId": "0f263884-af03-49ef-fa1d-20227a945333"
   },
   "outputs": [],
   "source": [
    "!ls raw_data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wLhyPugMJJfa",
   "metadata": {
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1702411868970,
     "user": {
      "displayName": "Martien Pilots",
      "userId": "08389853870944120926"
     },
     "user_tz": -60
    },
    "id": "wLhyPugMJJfa"
   },
   "outputs": [],
   "source": [
    "\n",
    "%cp raw_data/models/\"Unet_Res50_Unfreeze_ImageNet_WithMasks_256pix\".h5 /content/drive/MyDrive/data/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vnXHkFx4oMur",
   "metadata": {
    "id": "vnXHkFx4oMur"
   },
   "source": [
    "## Training Records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5IZo2zGNoLpi",
   "metadata": {
    "id": "5IZo2zGNoLpi"
   },
   "source": [
    "09/12/2023 23:34\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   Model: unet_4deep_16in_256pix\n",
    "*   optimizer: 'adam', loss: sm.losses.bce_jaccard_loss, metrics: sm.metrics.\n",
    "    iou_score\n",
    "*   Trainable params: 1941173\n",
    "*   Data: 12851 train images; 3213 val images, loaded,preporcessed,splited by   \n",
    "      UnetDataGenerator\n",
    "*   Training: set up for 100 epochs, stopped at 6 epochs by early stopping,\n",
    "    Wall time: 29min 52s, GPU V100\n",
    "*   'loss': 0.5861780643463135,\n",
    "    'iou_score': 0.5779913663864136,\n",
    "    'val_loss':  0.5868656635284424],\n",
    "    'val_iou_score': 0.5775318145751953,\n",
    "    'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eEshzNoLJE",
   "metadata": {
    "id": "76eEshzNoLJE"
   },
   "source": [
    "10/12/2023 03:34\n",
    "\n",
    "* Model: unet_4deep_16in_1024pix\n",
    "\n",
    "* optimizer: 'adam', loss: sm.losses.bce_jaccard_loss, metrics: sm.metrics.\n",
    "  iou_score\n",
    "* Trainable params: 1941173\n",
    "* Data: image and label size: 1024, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping,        Wall time: 2h 8min 6s, GPU V100\n",
    "* 'loss':  0.6727234125137329, 'iou_score': 0.50568687915802, 'val_loss': 0.6704270839691162, 'val_iou_score': 0.5068952441215515, 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9PTyj1Uyg",
   "metadata": {
    "id": "8fa9PTyj1Uyg"
   },
   "source": [
    "10/12/2023 10:34\n",
    "\n",
    "* Model: unet_4deep_64in_256pix\n",
    "\n",
    "* optimizer: 'adam', loss: sm.losses.bce_jaccard_loss, metrics: sm.metrics. iou_score\n",
    "\n",
    "* Trainable params: 31032005\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 29min 3s, GPU A100\n",
    "\n",
    "* 'loss': 0.5815900564193726, 'iou_score': 0.580341637134552, 'val_loss': 0.59281826019287112, 'val_iou_score': 0.5689619183540344, 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005] Slightly overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C6pYocaNuETv",
   "metadata": {
    "id": "C6pYocaNuETv"
   },
   "source": [
    "10/12/2023 16:34\n",
    "\n",
    "* Model: Unet_ResBackBone_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss: sm.losses.bce_jaccard_loss, metrics: sm.metrics. iou_score\n",
    "\n",
    "* Total params: 24456734 (93.30 MB)\n",
    "Trainable params: 24439384 (93.23 MB)\n",
    "Non-trainable params: 17350 (67.77 KB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 27min 3s, GPU A100\n",
    "\n",
    "* 'loss': 0.4621942937374115\n",
    " 'accuracy': 0.8795599341392517\n",
    " 'iou_score': 0.659989595413208\n",
    " 'val_loss': 0.48931652307510376\n",
    " 'val_accuracy':  0.8699352741241455\n",
    " 'val_iou_score': 0.6389757394790649\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kZsQpRbB6SoD",
   "metadata": {
    "id": "kZsQpRbB6SoD"
   },
   "source": [
    "10/12/2023 18:34\n",
    "\n",
    "* Model: Unet_ResBackBone_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:'categorical_crossentropy', metrics: accuracy, iou_score\n",
    "\n",
    "* Total params: 24456734 (93.30 MB)\n",
    "Trainable params: 24439384 (93.23 MB)\n",
    "Non-trainable params: 17350 (67.77 KB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 30min, GPU A100\n",
    "\n",
    "* 'loss': 0.28132763504981995\n",
    " 'accuracy': 0.8859129548072815\n",
    " 'iou_score': 0.5797572731971741\n",
    " 'val_loss': 0.31182384490966797\n",
    " 'val_accuracy':  0.8733996152877808\n",
    " 'val_iou_score': 0.5677776336669922\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x9pJzAdbyVTm",
   "metadata": {
    "id": "x9pJzAdbyVTm"
   },
   "source": [
    "11/12/2023 18:34\n",
    "\n",
    "* Model:Unet_Res34_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:categorical_focal_dice_loss = categorical_focal_loss + dice_loss, metrics: metrics=['accuracy', iou_score],metrics=['accuracy', iou_score]\n",
    "\n",
    "* Total params: 24456734 (93.30 MB)\n",
    "Trainable params: 24439384 (93.23 MB)\n",
    "Non-trainable params: 17350 (67.77 KB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 30min, GPU A100\n",
    "\n",
    "* 'loss':  0.2820780277252197\n",
    " 'accuracy': 0.8596312403678894\n",
    " 'iou_score': 0.6308621168136597\n",
    " 'val_loss': 0.2873755097389221\n",
    " 'val_accuracy':  0.8627598285675049\n",
    " 'val_iou_score': 0.6269094347953796\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_k_op8ttCKaB",
   "metadata": {
    "id": "_k_op8ttCKaB"
   },
   "source": [
    "11/12/2023 22:34\n",
    "\n",
    "* Model:Unet_Res34_Unfreeze_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:categorical_focal_dice_loss = categorical_focal_loss + dice_loss, metrics: metrics=['accuracy', iou_score],metrics=['accuracy', iou_score]\n",
    "\n",
    "* Weights ImageNet unfrozen\n",
    "Total params: 24456734 (93.30 MB)\n",
    "Trainable params: 3167640 (12.08 MB)\n",
    "Non-trainable params: 21289094 (81.21 MB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 30min, GPU A100\n",
    "\n",
    "* 'loss':\n",
    "  0.2606087327003479\n",
    " 'accuracy':\n",
    "  0.8644973635673523\n",
    " 'iou_score':\n",
    "  0.6521452069282532\n",
    " 'val_loss':\n",
    "  0.28726834058761597\n",
    " 'val_accuracy':\n",
    "  0.8619291186332703\n",
    " 'val_iou_score':\n",
    "  0.6286683082580566\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8FwdjTzaLFTe",
   "metadata": {
    "id": "8FwdjTzaLFTe"
   },
   "source": [
    "11/12/2023 23:34\n",
    "\n",
    "* Model:Unet_Res50_Unfreeze_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:categorical_focal_dice_loss = categorical_focal_loss + dice_loss, metrics: metrics=['accuracy', iou_score],metrics=['accuracy', iou_score]\n",
    "\n",
    "* Weights ImageNet unfrozen ResNet 50\n",
    "Total params: 32561694 (124.21 MB)\n",
    "Trainable params: 9059224 (34.56 MB)\n",
    "Non-trainable params: 23502470 (89.65 MB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 30min, GPU A100\n",
    "\n",
    "* 'loss':\n",
    "  0.2562115490436554\n",
    " 'accuracy':\n",
    "  0.8671656847000122\n",
    " 'iou_score':\n",
    "  0.6576858162879944\n",
    " 'val_loss':\n",
    "  0.27280107140541077\n",
    " 'val_accuracy':\n",
    "  0.8671523928642273\n",
    " 'val_iou_score':\n",
    "  0.6417083144187927\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u1g_pnAcUYQy",
   "metadata": {
    "id": "u1g_pnAcUYQy"
   },
   "source": [
    "12/12/2023 10:10\n",
    "\n",
    "* Model:Unet_Res101_Unfreeze_ImageNet_img_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:categorical_focal_dice_loss = categorical_focal_loss + dice_loss, metrics: metrics=['accuracy', iou_score],metrics=['accuracy', iou_score]\n",
    "\n",
    "* Weights ImageNet unfrozen ResNet 101\n",
    "Total params: 51606046 (196.86 MB)\n",
    "Trainable params: 9111448 (34.76 MB)\n",
    "Non-trainable params: 42494598 (162.10 MB)\n",
    "\n",
    "* Data: image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 30min, GPU A100\n",
    "\n",
    "*  'loss':\n",
    "  0.25483718514442444\n",
    " 'accuracy':\n",
    "  0.8705011606216431\n",
    " 'iou_score':\n",
    "  0.6602714657783508\n",
    " 'val_loss':\n",
    "  0.2740992307662964\n",
    " 'val_accuracy':\n",
    "  0.8686534762382507\n",
    " 'val_iou_score':\n",
    "  0.642823338508606\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qsge_kYKqTuW",
   "metadata": {
    "id": "Qsge_kYKqTuW"
   },
   "source": [
    "\n",
    "\n",
    "12/12/2023 21:10\n",
    "\n",
    "* Model:Unet_Res50_Unfreeze_ImageNet_WithMasks_256pix\n",
    "\n",
    "* optimizer: 'adam', loss:categorical_focal_dice_loss = categorical_focal_loss + dice_loss, metrics: metrics=['accuracy', iou_score],metrics=['accuracy', iou_score]\n",
    "\n",
    "* Weights ImageNet unfrozen ResNet 50\n",
    "Total params: 32561694 (124.21 MB)\n",
    "Trainable params: 9059224 (34.56 MB)\n",
    "Non-trainable params: 23502470 (89.65 MB)\n",
    "\n",
    "* Data: images overlapped with rover and 30 range masks. Image and label size: 256, 12851 train images; 3213 val images, loaded, preporcessed,splited by UnetDataGenerator\n",
    "\n",
    "* Training: set up for 100 epochs, stopped at 6 epochs by early stopping, Wall time: 44min 24s, GPU A100\n",
    "\n",
    "*   'loss':\n",
    "  0.23225967586040497\n",
    " 'accuracy':\n",
    "  0.8907396197319031\n",
    " 'iou_score':\n",
    "  0.6893125176429749\n",
    " 'val_loss':\n",
    "  0.26730599999427795\n",
    " 'val_accuracy':\n",
    "  0.8852259516716003\n",
    " 'val_iou_score':\n",
    "  0.6564145088195801\n",
    " 'lr': [0.001, 0.001, 0.001, 0.001, 0.000100000005, 0.000100000005]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92zfqmTQQ8g",
   "metadata": {
    "id": "c92zfqmTQQ8g"
   },
   "source": [
    "## Evaluate Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "TxXXhVfbQYEO",
   "metadata": {
    "id": "TxXXhVfbQYEO"
   },
   "outputs": [],
   "source": [
    "from drive_on_mars.model.model import initialize_model, compile_model, train_model\n",
    "from drive_on_mars.model.registry import save_model, save_results, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WS9j1DA9QQlL",
   "metadata": {
    "id": "WS9j1DA9QQlL"
   },
   "outputs": [],
   "source": [
    "# image and test label directories paths in COLAB\n",
    "\n",
    "# image_folder = \"raw_data/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "# test_folder = \"raw_data/ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min1-100agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9eef50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and label directories paths in LOCAL\n",
    "image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "test_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min1-100agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573a59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some inputs\n",
    "\n",
    "# Set image directory as image_folder, test label directory as label_folder, \"test\" as subfolder and split_percent to 1 to make the test data generator\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "input_shape = (256,256,3)\n",
    "split_percent = 1\n",
    "height=input_shape[0]\n",
    "width=input_shape[1]\n",
    "channels=input_shape[2]\n",
    "subfolder = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8a91b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 172 ms, sys: 30.7 ms, total: 202 ms\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test dataset generator \n",
    "\n",
    "testgen = UnetDataGenerator(image_folder,\n",
    "                             test_folder,\n",
    "                             input_shape,\n",
    "                             batch_size,\n",
    "                             num_classes,\n",
    "                             \"test\",\n",
    "                             split_percent,\n",
    "                            use_mask = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2931d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of generator: 322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f67365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Load latest model from local registry...\u001b[0m\n",
      "\u001b[34m\n",
      "Load latest model from disk...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 01:42:17.018393: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gargantua/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-13 01:42:17.018547: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-13 01:42:17.018587: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Jinjin): /proc/driver/nvidia/version does not exist\n",
      "2023-12-13 01:42:17.019586: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model compiled\n",
      "✅ Model loaded from local disk\n"
     ]
    }
   ],
   "source": [
    "res_backbone_model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b517b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of generator: 322\n",
      "Length of generator: 322\n",
      "Length of generator: 322\n",
      "21/21 [==============================] - 33s 1s/step - loss: 0.8497 - iou_score: 0.5387\n"
     ]
    }
   ],
   "source": [
    "res_backbone_score = res_backbone_model.evaluate(testgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9c43d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a475b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "DYtVbwDTnpTx",
   "metadata": {
    "id": "DYtVbwDTnpTx"
   },
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c97c47",
   "metadata": {
    "id": "e3c97c47",
    "outputId": "68d8639f-de31-40c7-d49b-897cf957c94b"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# es = callbacks.EarlyStopping(patience=2,restore_best_weights=True)\n",
    "# #modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format('First_model'), monitor=\"val_loss\", verbose=0, save_best_only=False)\n",
    "\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#           batch_size=16,\n",
    "#           epochs=10,\n",
    "#           validation_split=0.3,\n",
    "#           callbacks=[es],\n",
    "#           verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9d4e6",
   "metadata": {
    "id": "49b9d4e6",
    "outputId": "24da3e96-0d4c-401c-e25f-356a0049d11a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf753d99",
   "metadata": {
    "id": "cf753d99",
    "outputId": "5129fbc2-eb0f-45fc-9768-1bc95a831c85"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "es = callbacks.EarlyStopping(patience=2,restore_best_weights=True)\n",
    "#modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format('First_model'), monitor=\"val_loss\", verbose=0, save_best_only=False)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=16,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45141db",
   "metadata": {
    "id": "f45141db",
    "outputId": "8b880e80-4ade-4eb9-f9e1-bfc957c2b498"
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f884f6",
   "metadata": {
    "id": "38f884f6",
    "outputId": "6d3aabf8-7d00-42b7-dfb9-41b67f3f3385"
   },
   "outputs": [],
   "source": [
    "# def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "#     if axs is not None:\n",
    "#         ax1, ax2 = axs\n",
    "#     else:\n",
    "#         f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "#     if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "#         exp_name = '_' + exp_name\n",
    "#     ax1.plot(history.history['loss'], label = 'train' + exp_name)\n",
    "#     ax1.plot(history.history['val_loss'], label = 'val' + exp_name)\n",
    "#     ax1.set_ylim(0., 2.2)\n",
    "#     ax1.set_title('loss')\n",
    "#     ax1.legend()\n",
    "\n",
    "#     ax2.plot(history.history['iou_score'], label='train iou'  + exp_name)\n",
    "#     ax2.plot(history.history['val_iou_score'], label='val iou'  + exp_name)\n",
    "#     ax2.set_ylim(0, 0.5)\n",
    "#     ax2.set_title('iou')\n",
    "#     ax2.legend()\n",
    "#     return (ax1, ax2)\n",
    "\n",
    "# plot_history(history)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c8d87",
   "metadata": {
    "id": "5c1c8d87"
   },
   "outputs": [],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mhQ0992mZs2b",
    "DYtVbwDTnpTx"
   ],
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
