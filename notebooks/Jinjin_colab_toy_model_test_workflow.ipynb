{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b642a3",
   "metadata": {},
   "source": [
    "# Colab Toy Model Test Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b46006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from random import shuffle\n",
    "import glob\n",
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.utils import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "# Segmentation Models\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from segmentation_models.losses import CategoricalFocalLoss, DiceLoss\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495b4e2",
   "metadata": {},
   "source": [
    "## Model Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de881c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and label directories paths\n",
    "#image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "#label_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.open(\"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr/NLA_397681372EDR_F0020000AUT_04096M1.JPG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a607f6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random visualization of overlapped image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b23e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "edr_files = os.listdir(image_folder)\n",
    "trlab_files = os.listdir(label_folder)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "c = 0\n",
    "\n",
    "# preparing X and y\n",
    "for lab_name in trlab_files:\n",
    "    img_name = lab_name[:-4] + \".JPG\"\n",
    "    \n",
    "    if img_name in edr_files:\n",
    "        \n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr, dsize = (256, 256))\n",
    "        \n",
    "        lab_path = os.path.join(label_folder, lab_name)\n",
    "        lab_arr = cv2.imread(lab_path, 0)\n",
    "        lab_arr = cv2.resize(lab_arr, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "        \n",
    "        X.append(img_arr)\n",
    "        y.append(lab_arr)\n",
    "        \n",
    "    c += 1\n",
    "    if c >= 100:\n",
    "        break\n",
    "        \n",
    "X = np.asarray(X, dtype = np.float32) / 255.0\n",
    "y = np.array(y, dtype = np.uint8)\n",
    "\n",
    "# 0 - soil\n",
    "# 1 - bedrock\n",
    "# 2 - sand\n",
    "# 3 - big rock\n",
    "# 255 -> 4 - NULL (no label)\n",
    "\n",
    "\n",
    "# keeping integer values in labels will help us in segmentation task (UNet)\n",
    "y[y==255] = 4\n",
    "\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e9459",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "n = random.randint(0, len(X))\n",
    "print(np.unique(y[n]))\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.imshow(X[n])\n",
    "plt.imshow(y[n], alpha = 0.1)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4c0f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907c8b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(np.unique(y[255]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8622a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The 3 channels of each image are the same\n",
    "#print(X[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc39bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(X[0][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8537d1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(X[0][:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc29ba3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Build a customized data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae646f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# image and label directories paths\n",
    "#dataset_path = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl\"\n",
    "image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "label_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2643e40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#img_names = sorted(os.listdir(image_folder))\n",
    "#lab_names = sorted(os.listdir(label_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713d10e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#img_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c50f82",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lab_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define a customized data generator\n",
    "class UnetDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_folder, label_folder, input_shape, batch_size, num_classes, subfolder, split_percent):\n",
    "        self.image_folder       = image_folder\n",
    "        self.label_folder       = label_folder\n",
    "        self.input_shape        = input_shape\n",
    "        self.batch_size         = batch_size\n",
    "        self.num_classes        = num_classes\n",
    "        self.subfolder          = subfolder\n",
    "        self.split_percent      = split_percent\n",
    "        self.path_df            = self.make_df()\n",
    "        self.split_df()\n",
    "\n",
    "    def __len__(self):\n",
    "        print(\"Length of generator:\", len(self.path_df))\n",
    "        return math.ceil(len(self.path_df) / float(self.batch_size))\n",
    "    \n",
    "    def make_df(self):      \n",
    "        img_list = [f for f in os.listdir(self.image_folder) if f.endswith('.JPG')]\n",
    "        lab_list = [f for f in os.listdir(self.label_folder) if f.endswith('.png')]\n",
    "        \n",
    "        path_df = pd.DataFrame(columns=[\"image_path\",\"label_path\"])\n",
    "        \n",
    "        for label_name in lab_list:\n",
    "            image_name = label_name.replace('.png', '.JPG')\n",
    "            if image_name in img_list:\n",
    "                path_df = path_df.append({\n",
    "                    \"image_path\": os.path.join(self.image_folder, image_name),\n",
    "                    \"label_path\": os.path.join(self.label_folder, label_name)\n",
    "                }, ignore_index=True)\n",
    "        return path_df\n",
    "    \n",
    "   \n",
    "    \n",
    "    def split_df(self):\n",
    "        if self.subfolder == \"train\":\n",
    "            self.path_df = self.path_df.iloc[:int(len(self.path_df) * self.split_percent)]\n",
    "        elif self.subfolder == \"val\":\n",
    "            self.path_df = self.path_df.iloc[int(len(self.path_df) * self.split_percent):]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_images  = []\n",
    "        output_targets = []\n",
    "\n",
    "        #-------------------------------#\n",
    "        #   Calculate start indice and end indice of the batch\n",
    "        #-------------------------------#  \n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.path_df)) # Make sure that we can load all the data of the last batch\n",
    "\n",
    "        for i in range(start, end):  \n",
    "            \n",
    "            #-------------------------------#\n",
    "            #   Get image path and label path of each batch from path_df\n",
    "            #-------------------------------#                     \n",
    "            jpg = self.path_df.iloc[i][\"image_path\"]\n",
    "            png = self.path_df.iloc[i][\"label_path\"]\n",
    "                \n",
    "            #-------------------------------#\n",
    "            #   Transform images and labels to numpy array, resize them\n",
    "            #   Set the background label to 4\n",
    "            #-------------------------------#\n",
    "\n",
    "            jpg = cv2.imread(jpg)           \n",
    "            png = cv2.imread(png,0)\n",
    "                \n",
    "            jpg = cv2.resize(jpg, dsize = (int(self.input_shape[0]), int(self.input_shape[1])))\n",
    "            png = cv2.resize(png, dsize = (int(self.input_shape[0]), int(self.input_shape[1])), \n",
    "                                      interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            png[png == 255] = 4\n",
    "\n",
    "            #-------------------------------------------------------#\n",
    "            #   One hot encode the labels\n",
    "            #-------------------------------------------------------#\n",
    "                \n",
    "            seg_labels = np.eye(self.num_classes)[png.reshape([-1])]                \n",
    "            seg_labels = seg_labels.reshape((int(self.input_shape[0]), int(self.input_shape[1]), self.num_classes))\n",
    "\n",
    "            input_images.append(jpg)\n",
    "            output_targets.append(seg_labels)\n",
    "\n",
    "        input_images = np.asarray(input_images)\n",
    "        output_targets = np.array(output_targets)\n",
    "\n",
    "        \n",
    "        return input_images, output_targets\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1283bd",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a customized data generator\n",
    "class UnetDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_folder, label_folder, input_shape, batch_size, num_classes, subfolder, split_percent, use_mask = False):\n",
    "        self.image_folder       = image_folder\n",
    "        self.label_folder       = label_folder\n",
    "        self.input_shape        = input_shape\n",
    "        self.batch_size         = batch_size\n",
    "        self.num_classes        = num_classes\n",
    "        self.subfolder          = subfolder\n",
    "        self.split_percent      = split_percent\n",
    "        self.path_df            = self.make_df()\n",
    "        self.split_df()\n",
    "        self.use_mask           = use_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        print(\"Length of generator:\", len(self.path_df))\n",
    "        return math.ceil(len(self.path_df) / float(self.batch_size))    \n",
    "    \n",
    "    def make_df(self):      \n",
    "        img_list = [f for f in os.listdir(self.image_folder) if f.endswith('.JPG')]\n",
    "        lab_list = [f for f in os.listdir(self.label_folder) if f.endswith('.png')]\n",
    "\n",
    "        \n",
    "        path_df = pd.DataFrame(columns=[\"image_path\", \"label_path\", \"rover_mask_path\", \"range_mask_path\"])\n",
    "\n",
    "        for label_name in lab_list:\n",
    "            if self.subfolder in (\"train\", \"val\"):\n",
    "                image_name = label_name.replace('.png', '.JPG')\n",
    "                rover_mask_name = label_name.replace('EDR', 'MXY')  \n",
    "                range_mask_name = label_name.replace('EDR', 'RNG')  \n",
    "                \n",
    "            elif self.subfolder == 'test':\n",
    "                image_name = label_name.replace('_merged.png', '.JPG')\n",
    "                rover_mask_name = label_name.replace('_merged.png', '.png').replace('EDR', 'MXY')   \n",
    "                range_mask_name = label_name.replace('_merged.png', '.png').replace('EDR', 'RNG')  \n",
    "            \n",
    "            parent_folder = os.path.dirname(self.image_folder)\n",
    "            rover_mask_path = os.path.join(parent_folder,'mxy', rover_mask_name)\n",
    "            range_mask_path = os.path.join(parent_folder,'rng-30m', range_mask_name)\n",
    "\n",
    "            if image_name in img_list and os.path.exists(rover_mask_path) and os.path.exists(range_mask_path):\n",
    "                new_row = pd.DataFrame([{\n",
    "                \"image_path\": os.path.join(self.image_folder, image_name),\n",
    "                \"label_path\": os.path.join(self.label_folder, label_name),\n",
    "                \"rover_mask_path\": rover_mask_path,\n",
    "                \"range_mask_path\": range_mask_path\n",
    "                }])\n",
    "                path_df = pd.concat([path_df, new_row], ignore_index=True)\n",
    "        \n",
    "        return path_df\n",
    "\n",
    "  \n",
    "    \n",
    "    def split_df(self):\n",
    "        if self.subfolder in [\"train\",\"test\"]:\n",
    "            self.path_df = self.path_df.iloc[:int(len(self.path_df) * self.split_percent)]\n",
    "        elif self.subfolder == \"val\":\n",
    "            self.path_df = self.path_df.iloc[int(len(self.path_df) * self.split_percent):]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_images  = []\n",
    "        output_targets = []\n",
    "\n",
    "        #-------------------------------#\n",
    "        #   Calculate start indice and end indice of the batch\n",
    "        #-------------------------------#  \n",
    "        start = index * self.batch_size\n",
    "        end = min((index + 1) * self.batch_size, len(self.path_df)) # Make sure that we can load all the data of the last batch\n",
    "\n",
    "        for i in range(start, end):  \n",
    "            \n",
    "            #-------------------------------#\n",
    "            #   Get image,label,rover mask and range mask path of each batch from path_df\n",
    "            #-------------------------------#                     \n",
    "            jpg = self.path_df.iloc[i][\"image_path\"]\n",
    "            png = self.path_df.iloc[i][\"label_path\"]\n",
    "            rover = self.path_df.iloc[i][\"rover_mask_path\"]\n",
    "            rng = self.path_df.iloc[i][\"range_mask_path\"]\n",
    "            \n",
    "            #-------------------------------#\n",
    "            #   Load both range and rover masks combined\n",
    "            #-------------------------------#           \n",
    "            rover_array = cv2.imread(rover)\n",
    "            rng_array = cv2.imread(rng)\n",
    "            # reversing mask to only keep the image out of the mask\n",
    "            mask_combined = (1-rover_array) * (1-rng_array)\n",
    "      \n",
    "            #-------------------------------#\n",
    "            #   Transform images and labels to numpy array, resize them\n",
    "            #   Set the background label to 4\n",
    "            #-------------------------------#\n",
    "\n",
    "            jpg = cv2.imread(jpg)\n",
    "            if self.use_mask:\n",
    "                jpg = jpg * mask_combined            \n",
    "            \n",
    "            png = cv2.imread(png,0)\n",
    "                \n",
    "            jpg = cv2.resize(jpg, dsize = (int(self.input_shape[0]), int(self.input_shape[1])))\n",
    "            png = cv2.resize(png, dsize = (int(self.input_shape[0]), int(self.input_shape[1])), \n",
    "                                      interpolation = cv2.INTER_NEAREST)\n",
    "\n",
    "            png[png == 255] = 4\n",
    "\n",
    "            #-------------------------------------------------------#\n",
    "            #   One hot encode the labels\n",
    "            #-------------------------------------------------------#\n",
    "                \n",
    "            seg_labels = np.eye(self.num_classes)[png.reshape([-1])]                \n",
    "            seg_labels = seg_labels.reshape((int(self.input_shape[0]), int(self.input_shape[1]), self.num_classes))\n",
    "\n",
    "            input_images.append(jpg)\n",
    "            output_targets.append(seg_labels)\n",
    "\n",
    "        input_images = np.asarray(input_images)\n",
    "        output_targets = np.array(output_targets)\n",
    "\n",
    "        \n",
    "        return input_images, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da146da4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "                \n",
    "            #mask_list = []\n",
    "            #for n in range(0, self.num_classes ):  # Assurez-vous que les classes commencent à 0\n",
    "            #    mask = (png == i).astype(np.float32)  # Crée un masque pour chaque classe\n",
    "            #    mask_list.append(mask)\n",
    "\n",
    "            ## Empilage des masques pour former 5 canaux\n",
    "            #seg_labels = np.stack(mask_list, axis=-1)\n",
    "                \n",
    "            #import pdb\n",
    "            #pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9260d",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lab_255 = os.path.join(dataset_path, \"labels/train\", lab_files[255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e77b41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cv2.imread(lab_255).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78cce2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cv2.imread(lab_255,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5596b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cv2.imread(lab_255,0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03dcf2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cv2.imread(lab_255,0).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06681f54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cv2.imread(lab_255,0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753397b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(cv2.imread(lab_255,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513aff7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#array_lab = cv2.imread(lab_255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508753e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#resize_lab = cv2.resize(array_lab, dsize = (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2349427",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#resize_lab.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2325b50",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lab_arr = cv2.resize(array_lab, (256, 256), interpolation = cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03812632",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lab_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7291c5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(lab_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdd796",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lab_arr[lab_arr == 255] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d06f0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lab_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f318ad0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(lab_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe5bfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#reshaped = png.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d8af7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab22d09",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.eye(4)[reshaped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155618ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#png = cv2.imread(lab_255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa216c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c0d8c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#png_resize  = cv2.resize(png, dsize = (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f87567",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(png_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115472e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#resize_2 = cv2.resize(png, dsize = (256,256),interpolation = cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1755fe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(resize_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415ca56",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#resize_2[resize_2 == 255] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d980f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(resize_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3e72e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#reshape_2 = resize_2.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c79a22",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(reshape_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d87e15",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ohe = np.eye(5)[reshape_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb0e37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8a4a48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef9556",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ohe.reshape(256,256,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559e0e9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Base Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ca7a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Unet_model():\n",
    "    \"\"\"\n",
    "    Initialize the U-Net model\n",
    "    \"\"\"\n",
    "    #################\n",
    "    #    Params    #\n",
    "    #################\n",
    "\n",
    "    n_classes=5\n",
    "    height=256\n",
    "    width=256\n",
    "    channels=3\n",
    "    inputs = Input((height, width, channels))\n",
    "\n",
    "    ############################\n",
    "    # Down Sampling - Encoding #\n",
    "    ############################\n",
    "\n",
    "    conv_1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    conv_1 = Dropout(0.1)(conv_1)\n",
    "    conv_1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_1)\n",
    "    pool_1 = MaxPooling2D((2, 2))(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_1)\n",
    "    conv_2 = Dropout(0.1)(conv_2)\n",
    "    conv_2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_2)\n",
    "    pool_2 = MaxPooling2D((2, 2))(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_2)\n",
    "    conv_3 = Dropout(0.1)(conv_3)\n",
    "    conv_3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_3)\n",
    "    pool_3 = MaxPooling2D((2, 2))(conv_3)\n",
    "\n",
    "    conv_4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_3)\n",
    "    conv_4 = Dropout(0.1)(conv_4)\n",
    "    conv_4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_4)\n",
    "    pool_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
    "\n",
    "    conv_5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_4)\n",
    "    conv_5 = Dropout(0.2)(conv_5)\n",
    "    conv_5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_5)\n",
    "\n",
    "    ############################\n",
    "    #  Up Sampling - Decoding  #\n",
    "    ############################\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv_5)\n",
    "    u6 = concatenate([u6, conv_4])\n",
    "    conv_6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    conv_6 = Dropout(0.2)(conv_6)\n",
    "    conv_6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv_6)\n",
    "    u7 = concatenate([u7, conv_3])\n",
    "    conv_7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    conv_7 = Dropout(0.1)(conv_7)\n",
    "    conv_7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv_7)\n",
    "    u8 = concatenate([u8, conv_2])\n",
    "    conv_8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    conv_8 = Dropout(0.2)(conv_8)\n",
    "    conv_8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv_8)\n",
    "    u9 = concatenate([u9, conv_1], axis=3)\n",
    "    conv_9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    conv_9 = Dropout(0.1)(conv_9)\n",
    "    conv_9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_9)\n",
    "\n",
    "    ################\n",
    "    # Output Layer #\n",
    "    ################\n",
    "\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(conv_9)\n",
    "\n",
    "    ########################\n",
    "    # Model initialization #\n",
    "    ########################\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a25c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initializing and compiling model\n",
    "model = Unet_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[iou_score] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cc183",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ResNet_Backbone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca57e8c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#%% pre-trained model\n",
    "\n",
    "# backbone choices: resnet34' resnet50' resnet101'\n",
    "BACKBONE = 'resnet50'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# define model\n",
    "# encoder_freeze=True (encoder_freeze: if ``True`` set all layers of encoder (backbone model) as non-trainable, default value is False.)\n",
    "# input_shape: shape of input data/image ``(H, W, C)``, in general case you do not need to set ``H`` and ``W`` shapes, just pass ``(None, None, C)`` to make your model be able to process images af any size, but ``H`` and ``W`` of input images should be divisible by factor ``32``.\n",
    "# decoder_filters=(256, 128, 64, 32, 16)\n",
    "# input_shape=(None, None, 3)\n",
    "model_resnet_backbone = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=num_classes, activation='softmax', encoder_freeze=True)\n",
    "\n",
    "model_resnet_backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112abe5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compile model with defined optimozer, loss and metrics\n",
    "\n",
    "# loss: dice_loss\n",
    "categorical_focal_loss = CategoricalFocalLoss()\n",
    "dice_loss = DiceLoss()\n",
    "categorical_focal_dice_loss = categorical_focal_loss + dice_loss\n",
    "# categorical_focal_jaccard_loss = categorical_focal_loss + jaccard_loss\n",
    "# iou_score = IOUScore() (threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round, as: metrics = [sm.metrics.IOUScore(threshold=0.5)])\n",
    "# class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.\n",
    "iou_score = sm.metrics.IOUScore(class_indexes={0,1,2,3,4}) \n",
    "metrics=['accuracy', iou_score]\n",
    "\n",
    "model_resnet_backbone.compile(optimizer='adam',loss=categorical_focal_dice_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa720d9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### DeeplabV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4c8cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ed1c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input, \n",
    "    num_filters=256, \n",
    "    kernel_size=(3, 3), \n",
    "    dilation_rate=1, \n",
    "    padding=\"same\", \n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters, \n",
    "        kernel_size=kernel_size, \n",
    "        dilation_rate=dilation_rate, \n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]),\n",
    "        interpolation=\"nearest\",\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c25da9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use a ResNet50 pretrained on ImageNet as the backbone model\n",
    "def DeeplabV3Plus(image_size, num_classes):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = preprocess_input(model_input)\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
    "        interpolation=\"nearest\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = convolution_block(x)\n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"nearest\",\n",
    "    )(x)\n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\")(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "\n",
    "deep_model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc918025",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = 'CategoricalCrossentropy'\n",
    "metrics=['accuracy', iou_score]\n",
    "deep_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a81b002",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MODEL = \"DeepLab_Res50_ImageNet_img_256pix\"\n",
    "\n",
    "modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format(MODEL),\n",
    "                                            monitor=\"val_iou_score\",\n",
    "                                            save_best_only = False)\n",
    "\n",
    "LR_reducer = callbacks.ReduceLROnPlateau(patience = 3,\n",
    "                                         monitor=\"val_iou_score\",\n",
    "                                         factor = 0.1,\n",
    "                                         min_lr = 0\n",
    "                                        )\n",
    "\n",
    "early_stopper = callbacks.EarlyStopping(patience = 5,\n",
    "                                        monitor=\"val_iou_score\",\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "deep_history = deep_model.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=100,\n",
    "          callbacks = [modelCheckpoint, LR_reducer, early_stopper],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e24c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.ylabel(\"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.ylabel(\"val_accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc483d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362535d9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating Train and val data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976c463",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split train and validation datasets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(#X,#y, output_targets, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79185cd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#len(lab_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f66456",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#len(img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db145832",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Some inputs\n",
    "#image_size = (256,256,3)\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "input_shape = (256,256,3)\n",
    "split_percent = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04670f6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# image and label directories paths\n",
    "#dataset_path = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl\"\n",
    "image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "label_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9165f0b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train dataset generator and validation dataset generator\n",
    "traingen = UnetDataGenerator(image_folder,\n",
    "                             label_folder,\n",
    "                             input_shape,                        \n",
    "                             batch_size,\n",
    "                             num_classes,\n",
    "                             \"train\",\n",
    "                             split_percent,\n",
    "                            use_mask = True)\n",
    "\n",
    "valgen = UnetDataGenerator(image_folder,\n",
    "                           label_folder,\n",
    "                           input_shape,                        \n",
    "                           batch_size,\n",
    "                           num_classes,\n",
    "                           \"val\",\n",
    "                           split_percent,\n",
    "                          use_mask = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84303a51",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#len(traingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea9685",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#len(valgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499ce83",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.unique(traingen[2][1][1,...][...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65749255",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.unique(valgen[2][1][1,...][...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393b247",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#traingen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83a479",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3391727",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70c3a1",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "es = callbacks.EarlyStopping(patience=2,restore_best_weights=True)\n",
    "#modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format('First_model'), monitor=\"val_loss\", verbose=0, save_best_only=False)\n",
    "\n",
    "\n",
    "history = model.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=1,\n",
    "          callbacks=[es],\n",
    "          verbose=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb721b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7932b3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['iou_score'], label='train iou'  + exp_name)\n",
    "    ax2.plot(history.history['val_iou_score'], label='val iou'  + exp_name)\n",
    "    ax2.set_ylim(0, 0.5)\n",
    "    ax2.set_title('iou')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e5141",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Res_Backbone Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e9294",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "es = callbacks.EarlyStopping(patience=2,restore_best_weights=True)\n",
    "#modelCheckpoint = callbacks.ModelCheckpoint(\"{}.h5\".format('First_model'), monitor=\"val_loss\", verbose=0, save_best_only=False)\n",
    "\n",
    "history_res_backbone=model_resnet_backbone.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=1,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468461b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "history_res_backbone.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7f449",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history_res_backbone, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history_res_backbone.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history_res_backbone.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history_res_backbone.history['iou_score'], label='train iou'  + exp_name)\n",
    "    ax2.plot(history_res_backbone.history['val_iou_score'], label='val iou'  + exp_name)\n",
    "    ax2.set_ylim(0, 0.5)\n",
    "    ax2.set_title('iou')\n",
    "    ax2.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history_res_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8b2c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_history(history_res_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2984fce",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f243c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image and label directories paths in LOCAL\n",
    "image_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/images/edr\"\n",
    "test_folder = \"/home/gargantua/code/TigerManon/08-Palette/ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min1-100agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6fd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some inputs\n",
    "\n",
    "# Set image directory as image_folder, test label directory as label_folder, \"test\" as subfolder and split_percent to 1 to make the test data generator\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "input_shape = (256,256,3)\n",
    "split_percent = 1\n",
    "height=input_shape[0]\n",
    "width=input_shape[1]\n",
    "channels=input_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1df426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 188 ms, sys: 18.7 ms, total: 207 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test dataset generator \n",
    "\n",
    "testgen = UnetDataGenerator(image_folder,\n",
    "                             test_folder,\n",
    "                             input_shape,\n",
    "                             batch_size,\n",
    "                             num_classes,\n",
    "                             \"test\",\n",
    "                             split_percent,\n",
    "                            use_mask = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7726775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of generator: 322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b73b8b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae76b9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# Load the image \n",
    "img = Image.open('cat.png') \n",
    "# Preprocess the image \n",
    "img = img.resize((256, 256)) \n",
    "img_array = image.img_to_array(img) \n",
    "img_array = np.expand_dims(img_array[:,:,:3], axis=0) \n",
    "img_array = img_array / 255.\n",
    "  \n",
    "# Load the model \n",
    "model = unet_model(input_shape=(256, 256, 3), num_classes=5) \n",
    "  \n",
    "# Make predictions \n",
    "predictions = model.predict(img_array) \n",
    "  \n",
    "# Convert predictions to a numpy array and resize to original image size \n",
    "predictions = np.squeeze(predictions, axis=0) \n",
    "predictions = np.argmax(predictions, axis=-1) \n",
    "predictions = Image.fromarray(np.uint8(predictions*255)) \n",
    "predictions = predictions.resize((img.width, img.height)) \n",
    "  \n",
    "# Save the predicted image \n",
    "predictions.save('predicted_image.jpg') \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221dd123",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def iou_score(gt, pr, class_weights=1., class_indexes=None, smooth=SMOOTH, per_image=False, threshold=None, **kwargs):\n",
    "    r\"\"\" The `Jaccard index`_, also known as Intersection over Union and the Jaccard similarity coefficient\n",
    "    (originally coined coefficient de communauté by Paul Jaccard), is a statistic used for comparing the\n",
    "    similarity and diversity of sample sets. The Jaccard coefficient measures similarity between finite sample sets,\n",
    "    and is defined as the size of the intersection divided by the size of the union of the sample sets:\n",
    "\n",
    "    .. math:: J(A, B) = \\frac{A \\cap B}{A \\cup B}\n",
    "\n",
    "    Args:\n",
    "        gt: ground truth 4D keras tensor (B, H, W, C) or (B, C, H, W)\n",
    "        pr: prediction 4D keras tensor (B, H, W, C) or (B, C, H, W)\n",
    "        class_weights: 1. or list of class weights, len(weights) = C\n",
    "        class_indexes: Optional integer or list of integers, classes to consider, if ``None`` all classes are used.\n",
    "        smooth: value to avoid division by zero\n",
    "        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n",
    "            else over whole batch\n",
    "        threshold: value to round predictions (use ``>`` comparison), if ``None`` prediction will not be round\n",
    "\n",
    "    Returns:\n",
    "        IoU/Jaccard score in range [0, 1]\n",
    "\n",
    "    .. _`Jaccard index`: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    backend = kwargs['backend']\n",
    "\n",
    "    gt, pr = gather_channels(gt, pr, indexes=class_indexes, **kwargs)\n",
    "    pr = round_if_needed(pr, threshold, **kwargs)\n",
    "    axes = get_reduce_axes(per_image, **kwargs)\n",
    "\n",
    "    # score calculation\n",
    "    intersection = backend.sum(gt * pr, axis=axes)\n",
    "    union = backend.sum(gt + pr, axis=axes) - intersection\n",
    "\n",
    "    score = (intersection + smooth) / (union + smooth)\n",
    "    score = average(score, per_image, class_weights, **kwargs)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b00792",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def iou_score(pred_mask, true_mask):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param pred_mask:  (height, width, num_classes)\n",
    "    :param true_mask:  (height, width, num_classes)\n",
    "    :return: IOU of each class\n",
    "    \"\"\"\n",
    "    ious = []\n",
    "    for c in range(pred_mask.shape[-1]): \n",
    "\n",
    "        pred_c = pred_mask[..., c]\n",
    "        true_c = true_mask[..., c]\n",
    "\n",
    "        intersection = np.logical_and(pred_c, true_c)\n",
    "        union = np.logical_or(pred_c, true_c)\n",
    "\n",
    "        # 计算 IOU\n",
    "        if np.sum(union) == 0:\n",
    "            iou = 0\n",
    "        else:\n",
    "            iou = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return ious\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c33e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "iou_scores = iou_score(pred_mask, true_mask)\n",
    "\n",
    "for i, iou in enumerate(iou_scores):\n",
    "    print(f\"Class {i} IOU Score: {iou}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d2554",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_iou_score(pred_mask, true_mask):\n",
    "    \"\"\"\n",
    "   :param pred_mask:  (height, width, num_classes)\n",
    "    :param true_mask:  (height, width, num_classes)\n",
    "    :return: IOU of all classes\n",
    "    \"\"\"\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "    \n",
    "    for c in range(pred_mask.shape[-1]):  \n",
    "        \n",
    "        pred_c = pred_mask[..., c]\n",
    "        true_c = true_mask[..., c]\n",
    "\n",
    "        intersection = np.logical_and(pred_c, true_c)\n",
    "        union = np.logical_or(pred_c, true_c)\n",
    "\n",
    "        total_intersection += np.sum(intersection)\n",
    "        total_union += np.sum(union)\n",
    "\n",
    "    if total_union == 0:\n",
    "\n",
    "        mean_iou = 0\n",
    "    else:\n",
    "        mean_iou = total_intersection / total_union\n",
    "    \n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b8c9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(mask, num_classes):\n",
    "    \"\"\"\n",
    "    将单通道的类别掩码转换为多通道的二进制形式。\n",
    "    \n",
    "    :param mask: 单通道掩码，每个像素值代表类别编号\n",
    "    :param num_classes: 类别总数\n",
    "    :return: 多通道的二进制掩码\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[mask]\n",
    "\n",
    "def mean_iou_score(pred_mask, true_mask, num_classes):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param pred_mask: 预测掩码，单通道，每个像素值代表类别编号\n",
    "    :param true_mask: 真实掩码，单通道，每个像素值代表类别编号\n",
    "    :param num_classes: 类别总数\n",
    "    :return: 所有类别的平均 IOU 分数\n",
    "    \"\"\"\n",
    "    # 将单通道掩码转换为多通道二进制形式\n",
    "    pred_mask_one_hot = one_hot_encode(pred_mask, num_classes)\n",
    "    true_mask_one_hot = one_hot_encode(true_mask, num_classes)\n",
    "\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "\n",
    "    for c in range(num_classes):  # 遍历每个类别\n",
    "        pred_c = pred_mask_one_hot[..., c]\n",
    "        true_c = true_mask_one_hot[..., c]\n",
    "\n",
    "        intersection = np.logical_and(pred_c, true_c)\n",
    "        union = np.logical_or(pred_c, true_c)\n",
    "\n",
    "        total_intersection += np.sum(intersection)\n",
    "        total_union += np.sum(union)\n",
    "\n",
    "    if total_union == 0:\n",
    "        mean_iou = 0\n",
    "    else:\n",
    "        mean_iou = total_intersection / total_union\n",
    "    \n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71a56e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc60bd43",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
